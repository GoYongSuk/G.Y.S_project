{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125eb259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a60b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a22191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e4dd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72703</th>\n",
       "      <td>This stuff is so yummy, I'll be buying it agai...</td>\n",
       "      <td>absolutely delish!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72874</th>\n",
       "      <td>If you aren't going to eat those Pop Tarts up ...</td>\n",
       "      <td>Expires Soon!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12276</th>\n",
       "      <td>My dogs all love the Dogswell Happy Hips Chick...</td>\n",
       "      <td>Happy Hips Make My Dogs Happy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44192</th>\n",
       "      <td>THe flavored pods are great.  It's nice when c...</td>\n",
       "      <td>Great Stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50686</th>\n",
       "      <td>Buyer beware.  You can order this supersized p...</td>\n",
       "      <td>Price Gouge in Effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22403</th>\n",
       "      <td>A pretzel is a pretzel right?  Wrong.  I was a...</td>\n",
       "      <td>How can a pretzel taste this good?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24635</th>\n",
       "      <td>Everything was just great. The food arrived as...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>Amazing punch of flavor in such a small wrappe...</td>\n",
       "      <td>Amazing flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37880</th>\n",
       "      <td>This is a very interesting tea because it requ...</td>\n",
       "      <td>great tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92809</th>\n",
       "      <td>Received the coffe sooner then was expected, w...</td>\n",
       "      <td>did not like the flavor of the coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60449</th>\n",
       "      <td>good deal on the energy drinks. That's the onl...</td>\n",
       "      <td>5 hour energy drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>The kids like to drink, drinking a can of the ...</td>\n",
       "      <td>good.......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>I am on a low carb diet and have lost 25 pound...</td>\n",
       "      <td>FANTASTIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85598</th>\n",
       "      <td>Bought this to add to a recipe by Jason Schiff...</td>\n",
       "      <td>Add it to your Manhattan!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47546</th>\n",
       "      <td>I have this on monthly re-order.  I have two d...</td>\n",
       "      <td>My dogs love this and its worth the price!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "72703  This stuff is so yummy, I'll be buying it agai...   \n",
       "72874  If you aren't going to eat those Pop Tarts up ...   \n",
       "12276  My dogs all love the Dogswell Happy Hips Chick...   \n",
       "44192  THe flavored pods are great.  It's nice when c...   \n",
       "50686  Buyer beware.  You can order this supersized p...   \n",
       "22403  A pretzel is a pretzel right?  Wrong.  I was a...   \n",
       "24635  Everything was just great. The food arrived as...   \n",
       "15931  Amazing punch of flavor in such a small wrappe...   \n",
       "37880  This is a very interesting tea because it requ...   \n",
       "92809  Received the coffe sooner then was expected, w...   \n",
       "60449  good deal on the energy drinks. That's the onl...   \n",
       "7726   The kids like to drink, drinking a can of the ...   \n",
       "1512   I am on a low carb diet and have lost 25 pound...   \n",
       "85598  Bought this to add to a recipe by Jason Schiff...   \n",
       "47546  I have this on monthly re-order.  I have two d...   \n",
       "\n",
       "                                          Summary  \n",
       "72703                          absolutely delish!  \n",
       "72874                               Expires Soon!  \n",
       "12276              Happy Hips Make My Dogs Happy!  \n",
       "44192                                 Great Stuff  \n",
       "50686                       Price Gouge in Effect  \n",
       "22403          How can a pretzel taste this good?  \n",
       "24635                                       Great  \n",
       "15931                              Amazing flavor  \n",
       "37880                                   great tea  \n",
       "92809       did not like the flavor of the coffee  \n",
       "60449                         5 hour energy drink  \n",
       "7726                                  good.......  \n",
       "1512                                    FANTASTIC  \n",
       "85598                   Add it to your Manhattan!  \n",
       "47546  My dogs love this and its worth the price!  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d8eb91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3609fb",
   "metadata": {},
   "source": [
    "### 데이터프레임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802f1a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c818fc",
   "metadata": {},
   "source": [
    "### 결측치 확인 (Null 값이 있는지 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91a48b11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dcf248",
   "metadata": {},
   "source": [
    "### 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737d2823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918c841",
   "metadata": {},
   "source": [
    "#### 단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있어요. 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법이에요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22918e83",
   "metadata": {},
   "source": [
    "[정규화 사전 출처](https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eed8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be62bb4",
   "metadata": {},
   "source": [
    "### 불용어(stopwords),  NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847ee30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8794d",
   "metadata": {},
   "source": [
    "함수의 하단을 보면, NLTK를 이용해 불용어를 제거하는 파트가 있는데, 이는 Text 전처리 시에서만 호출하고 이미 상대적으로 문장 길이가 짧은 Summary 전처리할 때는 호출하지 않을 예정이에요. Abstractive한 문장 요약 결과문이 자연스러운 문장이 되려면 이 불용어들이 Summary에는 남아 있는 게 더 좋을 것 같습니다. 이 처리를 위해서 함수의 인자로 remove_stopwords를 추가하고, if문을 추가했어요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88f9e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec55c1",
   "metadata": {},
   "source": [
    "### 전처리 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32241f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae9572",
   "metadata": {},
   "source": [
    "### 훈련 데이터 전체에 대해서 전처리를 수행해볼게요. 이때, Text의 경우에는 불용어를 제거하고, <br>Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f19fe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6db69d",
   "metadata": {},
   "source": [
    "Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d297991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "clean_summary = []\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e23db2",
   "metadata": {},
   "source": [
    "이렇게 텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해보는 것이 좋아요. 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있어요. 이렇게 되면 샘플 자체가 빈 값을 가지게 되겠죠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2e681",
   "metadata": {},
   "source": [
    "### 빈(empty) 값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37406fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "641aca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda152b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2449935",
   "metadata": {},
   "source": [
    "### Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9608e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAglElEQVR4nO3dfXRV9b3n8fcnD4CgLQ8y+ACIq9f2RnOn2GbU0dyOXFuvdq6Vu5ZTpR0vrZky3Cu59upaPuWPdubeWHVmai3tKoMNPrQSZbRV2+VtayUuV6Q6YutYNb1KvVWCKCCogARC8p0/zg49QBIgyTl7J/vzWuus7P07+5zzjbLzOb/f/u29FRGYmZllTUXaBZiZmfXHAWVmZpnkgDIzs0xyQJmZWSY5oMzMLJMcUGZmlkkOKDMzyyQH1BghaUfRo1fSrqL1Lw7h/c6V1FmKWs1GgqR6SWskvSdpq6SnJP27tOuykVOVdgE2MiLi6L5lSX8A/ktE/DK9isxKR9KHgJ8CfwusAsYBfw7sTrOuIyFJgCKiN+1asso9qDFOUoWk6yX9XtI7klZJmpo89z1JDxZte4ukxyVNAv4ZOKGoF3ZCWr+DWT8+ChARrRHRExG7IuIXEfGCpK9L+mHfhpLmSApJVcn6E5L+Kel97ZD0E0nTJN0r6X1Jz0qaU/T6kPR3kl6VtF3SP0r6SPL695N9alyy7RRJP5W0WdK2ZHlm0Xs9IalZ0lPAB8A1kp4r/sUkXS3p4ZL+1xslHFBjXyMwH/gPwAnANuC7yXPXAH8m6UuS/hxoABZGxE7gQuDNiDg6ebxZ/tLNBvQK0CPpbkkXSppyhK+/DLgcOBH4CPAr4E5gKtABfO2A7f8S+CRwFnAtsBz4z8AsoBZYkGxXkbzPScBsYBfwnQPe63JgEXAM8G3gZEk1Bzx/zxH+PmOSA2rsWww0RURnROwGvg5cIqkqIj6gsDN8E/gh0BgRPu5kmRcR7wP1QAB3AJslPSJpxmG+xZ0R8fuIeI/CaMHvI+KXEbEX+D/A6Qdsf2tEvB8RLwEvAr+IiNeKXn96Utc7EfFgRHwQEduBZgpfDovdFREvRcTeZJ+8n0LYIek0YA6F4cvcc0CNfScBP5b0rqR3KXw77AFmAETEM8BrgCiM5ZuNChHRERFfioiZFHoxJwDfOsyXv120vKuf9aP33/zwtpc0UdL/lvS6pPeBJ4HJkiqLtl9/wHvfDXwhOSZ1ObAqCa7cc0CNfeuBCyNictFjQkRsAJB0JTAeeJPC0EUfX+beRo2I+B1wF4Wg2glMLHr6uDKWcg3wMeDMiPgQ8KmkXUXb7LdvRcTTwB4Kkzy+APygDHWOCg6osW8Z0CzpJABJ0yVdnCx/FPgnCsMLlwPXSpqbvO5tYJqkD5e/ZLPBSfpTSdf0TUCQNIvCcaCngeeBT0manfz7vaGMpR1DoUf1bjIZ6cBjWQO5h8Kxqu6IaC9VcaONA2rsux14BPiFpO0UduAzkxlNPwRuiYj/FxGvAjcCP5A0PvlG2gq8lgwPehafZcl24EzgGUk7Kfy7fhG4JiIeo3Bc5wXgOcp7POdbwFHAlqSmnx3m635Aoff3w0NtmCfyDQvNzNIl6ShgE/CJ5Mui4R6UmVkW/C3wrMNpf76ShJlZipIrv4jC+YpWxEN8ZmaWSR7iMzOzTMr0EN+xxx4bc+bMSbsMsyPy3HPPbYmI6Wl8tvcZG40G2mcyHVBz5sxh7dq1aZdhdkQkvZ7WZ3ufsdFooH3GQ3xmZpZJDigzM8skB5SZmWWSA8rMzDLJAWVmZpnkgDIzs0xyQOVMa2srtbW1VFZWUltbS2tra9olmWWa95n0ZPo8KBtZra2tNDU10dLSQn19Pe3t7TQ0NACwYMGClKszyx7vMymLiMw+PvnJT4aNnNNOOy1Wr169X9vq1avjtNNOS6misQlYG95nxgTvM+Ux0D6T6YvF1tXVhc+KHzmVlZV0dXVRXV29r627u5sJEybQ09OTYmVji6TnIqIujc/2PjOyvM+Ux0D7jI9B5UhNTQ3t7fvfTbq9vZ2ampqUKjLLNu8z6XJA5UhTUxMNDQ20tbXR3d1NW1sbDQ0NNDU1pV2aWSZ5n0nXISdJSFoB/BWwKSJqk7b/AVwE7AF+D3w5It5NnrsBaAB6gL+PiJ8n7RcAtwOVwPcj4uYR/21sUH0HdRsbG+no6KCmpobm5mYf7DUbgPeZdB3yGJSkTwE7gHuKAup8YHVE7JV0C0BEXCfpVKAVOAM4Afgl8NHkrV4BPgN0As8CCyLi5cE+2+PpNhr5GJTZkRnyMaiIeBLYekDbLyJib7L6NDAzWb4YuC8idkfEvwLrKITVGcC6iHgtIvYA9yXbmpmZ9WskjkFdAfxzsnwisL7ouc6kbaD2g0haJGmtpLWbN28egfLMzGw0GlZASWoC9gL3jkw5EBHLI6IuIuqmT0/lpqRmZpYBQ76ShKQvUZg8cV788UDWBmBW0WYzkzYGaTczMzvIkHpQyYy8a4HPRcQHRU89Alwmabykk4FTgP9LYVLEKZJOljQOuCzZ1szMrF+HM828FTgXOFZSJ/A14AZgPPCYJICnI2JxRLwkaRXwMoWhvysjoid5nyXAzylMM18RES+V4PcxM7Mx4pABFRH9TfhvGWT7ZqC5n/ZHgUePqDozM8stX0nCzMwyyQFlZmaZ5IAyM7NMckCZmVkmOaDMzCyTHFBmZpZJDigzM8skB5SZmWWSA8osZZJmSWqT9LKklyRdlbR/XdIGSc8nj8+mXatZOTmgzNK3F7gmIk4FzgKuTG7+CXBbRMxNHr4SSwpaW1upra2lsrKS2tpaWltb0y4pN4Z8NXMzGxkRsRHYmCxvl9TBAPdLs/JqbW2lqamJlpYW6uvraW9vp6GhAcC3fS8D96DMMkTSHOB04JmkaYmkFyStkDQlvcryqbm5mZaWFubNm0d1dTXz5s2jpaWF5uaDLjdqJeCAMssISUcDDwJfjYj3ge8BHwHmUuhh/a8BXue7UJdIR0cH9fX1+7XV19fT0dGRUkX54oAyywBJ1RTC6d6I+BFARLwdET0R0QvcAZzR32t9F+rSqampob29fb+29vZ2ampqUqooXxxQZilT4aZqLUBHRHyzqP34os3+Gnix3LXlXVNTEw0NDbS1tdHd3U1bWxsNDQ00NTWlXVoueJKEWfrOAS4Hfivp+aTtRmCBpLlAAH8A/msaxeVZ30SIxsZGOjo6qKmpobm52RMkysQBZZayiGgH1M9TnlaeAWvWrGHdunX09vaybt061qxZ44AqEw/xmZkNoLGxkWXLlnHTTTexc+dObrrpJpYtW0ZjY2PapeWCA8rMbAB33HEHt9xyC1dffTUTJ07k6quv5pZbbuGOO+5Iu7RccECZmQ1g9+7dLF68eL+2xYsXs3v37pQqyhcHlJnZAMaPH8+yZcv2a1u2bBnjx49PqaJ88SQJM7MBfOUrX+G6664DCj2nZcuWcd111x3Uq7LScECZmQ1g6dKlANx4441cc801jB8/nsWLF+9rt9JyQJmZDWLp0qUOpJT4GJSZ2SBmz56NpH2P2bNnp11SbhwyoJKrKG+S9GJR21RJj0l6Nfk5JWmXpG9LWpdcgfkTRa9ZmGz/qqSFpfl1zMxGzuzZs1m/fj1nn302b775JmeffTbr1693SJXJ4fSg7gIuOKDteuDxiDgFeDxZB7gQOCV5LKJwNWYkTQW+BpxJ4YKXX/OtA8ws6/rC6amnnuL444/nqaee2hdSVnqHDKiIeBLYekDzxcDdyfLdwPyi9nui4GlgcnLBy78EHouIrRGxDXiMg0PPzCxzHnjggUHXrXSGegxqRnIXUIC3gBnJ8olA8VeLzqRtoPaD+N42ZpYll1xyyaDrVjrDniQREUHhassjwve2MbOsmDVrFmvWrOGcc85h48aNnHPOOaxZs4ZZs2alXVouDHWa+duSjo+IjckQ3qakfQNQ/H9uZtK2ATj3gPYnhvjZZmZl8cYbbzB79mzWrFnDCSecABRC64033ki5snwYag/qEaBvJt5C4OGi9r9JZvOdBbyXDAX+HDhf0pRkcsT5SZuZWaa98cYbRMS+h8OpfA7Zg5LUSqH3c6ykTgqz8W4GVklqAF4HPp9s/ijwWWAd8AHwZYCI2CrpH4Fnk+3+e0QcOPHCzCxzCjc83l/hyIaV2iEDKiIGujPXef1sG8CVA7zPCmDFEVVnZpaivnCqrq6mra2NefPm0d3djSSHVBn4UkdmZoOorq5mz549AOzZs4dx48bR3d2dclX54EsdmZkNoq2tbdB1Kx0HlJnZIObNmzfoupWOA8rMbBDd3d2MGzeOp556ysN7ZeZjUGZmA4gIJNHd3U19ff1+7VZ6Digzs0E4jNLjgDIzG0RFRcV+ISWJ3t7eFCvKDx+DMjMbQF84TZgwgaeffpoJEyYQEVRU+E9nObgHZWY2gL5w2rVrFwC7du3iqKOOoqurK+XK8sFfA8zMBvHEE08Mum6l44AyMxvEueeeO+i6lY4DysxsAJLo6uriqKOO4plnntk3vNffBWRt5PkYlJnZAHp7e6moqKCrq4uzzjoL8Cy+cnJAmZkNwmGUHg/xmaVM0ixJbZJelvSSpKuS9qmSHpP0avJzStq15pGkgx5WHg6onGltbaW2tpbKykpqa2tpbW1NuySDvcA1EXEqcBZwpaRTgeuBxyPiFODxZN3KqDiM7rvvvn7brXQcUDnS2trKVVddxc6dOwHYuXMnV111lUMqZRGxMSJ+nSxvBzqAE4GLgbuTze4G5qdSoBERXHrppb7sUZk5oHLk2muvpaqqihUrVtDV1cWKFSuoqqri2muvTbs0S0iaA5wOPAPMiIiNyVNvATMGeM0iSWslrd28eXN5Cs2R4p5Tf+tWOg6oHOns7GThwoU0NjYyYcIEGhsbWbhwIZ2dnWmXZoCko4EHga9GxPvFz0Xhq3u/X98jYnlE1EVE3fTp08tQab5cdtllg65b6TigcubOO+9k6dKldHV1sXTpUu688860SzJAUjWFcLo3In6UNL8t6fjk+eOBTWnVl3eSuP/++33sqcwcUDlSVVV10M3Wuru7qary2QZpUuGvXgvQERHfLHrqEWBhsrwQeLjcteVd8TGn4p6Tj0WVh/8y5UhPTw+VlZVcccUVvP7665x00klUVlbS09OTdml5dw5wOfBbSc8nbTcCNwOrJDUArwOfT6e8fHMYpccBlSOnnnoq8+fP56GHHkISkyZN4otf/CIPPfRQ2qXlWkS0AwONHZ1XzlrsYP0N6zm0ysNDfDnS1NTEypUr9zsGtXLlSpqamtIuzSyTisPpgQce6LfdSsc9qBxZsGABAI2NjXR0dFBTU0Nzc/O+djPrX1+PKSIcTmXkgMqZBQsWOJDMjkBxz6lv/ZJLLkmpmnwZ1hCfpH9Irh32oqRWSRMknSzpGUnrJN0vaVyy7fhkfV3y/JwR+Q3MzErowDByOJXPkANK0onA3wN1EVELVAKXAbcAt0XEnwDbgIbkJQ3AtqT9tmQ7M7PMk8SDDz7o4b0yG+4kiSrgKElVwERgI/AXQF+fuPj6YcXXFXsAOE/+v21mGVY8W6+45+RZfOUx5ICKiA3A/wTeoBBM7wHPAe9GxN5ks04KF70k+bk+ee3eZPtpB76vrytmZlkSEQc9rDyGM8Q3hUKv6GTgBGAScMFwC/J1xcwsS3w/qPQMZ4jv08C/RsTmiOgGfkThjPjJyZAfwExgQ7K8AZgFkDz/YeCdYXy+mVlJFYfRTTfd1G+7lc5wAuoN4CxJE5NjSecBLwNtQN9gbfH1w4qvK3YJsDrcVzazUSAiuOGGGzy8V2bDOQb1DIXJDr8Gfpu813LgOuBqSesoHGNqSV7SAkxL2q/Gdwc1s1GguOfU37qVjrL8jaCuri7Wrl2bdhlmR0TScxFRl8Zne58ZWX1DecV/J/trs+EZaJ/xtfjMzA5BEt/4xjd87KnMHFBmZgMo7iXdeOON/bZb6TigzMwskxxQZmYDKB7Su/LKK/ttt9JxQJmZHUJE8J3vfMdDe2XmgDIzG0Rxz6m/dSsdB5SZ2SC++93vDrpupeOAMjM7BEksWbLEx57KzAGVM62trdTW1lJZWUltbS2tra1pl2SWWcXHnIp7Tj4WVR6+5XuOtLa20tTUREtLC/X19bS3t9PQULifpG8Db9Y/h1F63IPKkebmZlpaWpg3bx7V1dXMmzePlpYWmpub0y7NLLN8u430OKBypKOjg/r6+v3a6uvr6ejoSKkis2wrDqOLLrqo33YrHQ/x5UhNTQ3t7e3MmzdvX1t7ezs1NTUpVmWWff1dLNZKzz2oHGlqaqKhoYG2tja6u7tpa2ujoaGBpqamtEszy6zinlN/61Y67kHlSN9EiMbGRjo6OqipqaG5udkTJMwG8ZOf/GTQdSsdB1TOLFiwwIFkdoQkcdFFFzmcysxDfGZmAyg+9lQcTp56Xh7uQZmZDcJhlB73oMxSJmmFpE2SXixq+7qkDZKeTx6fTbPGPPN5UOlxQJml7y7ggn7ab4uIucnj0TLXZOw/pXzu3Ln9tlvpOKByxtfiy56IeBLYmnYdNrCI4De/+Y2H+8rMAZUjfdfiW7p0KV1dXSxdupSmpiaHVHYtkfRCMgQ4ZaCNJC2StFbS2s2bN5ezvlwo7jn1t26loyx/I6irq4u1a9emXcaYUVtby/z583nooYf2nQfVt/7iiy8e+g3ssEh6LiLqjvA1c4CfRkRtsj4D2AIE8I/A8RFxxaHex/vMyOobyuvvShJZ/ts52gy0z3gWX468/PLLbNq0iUmTJgGwc+dOli9fzpYtW1KuzA4UEW/3LUu6A/hpiuXkniTmzp3L888/n3YpueIhvhyprKxk165dwB+//e3atYvKyso0y7J+SDq+aPWvAXdxU1DcSyoOJ/eeymNYASVpsqQHJP1OUoekfy9pqqTHJL2a/JySbCtJ35a0LhlX/8TI/Ap2uPbu3csHH3xAY2MjO3bsoLGxkQ8++IC9e/emXVquSWoFfgV8TFKnpAbgVkm/lfQCMA/4h1SLzLGIOOhh5THcHtTtwM8i4k+BjwMdwPXA4xFxCvB4sg5wIXBK8lgEfG+Yn21DcOmll7JixQqOOeYYVqxYwaWXXpp2SbkXEQsi4viIqI6ImRHREhGXR8SfRcS/jYjPRcTGtOvMK58HlZ4hB5SkDwOfAloAImJPRLwLXAzcnWx2NzA/Wb4YuCcKngYmHzCMYWWwevXq/WbxrV69Ou2SzDJroDBySJXHcCZJnAxsBu6U9HHgOeAqYEbRt723gBnJ8onA+qLXdyZt+30zlLSIQg+L2bNnD6M8O9DMmTPZsWMHV1xxBa+//jonnXQSu3fvZubMmWmXZpZpvh9UOoYzxFcFfAL4XkScDuzkj8N5AETh/+oRDdhGxPKIqIuIuunTpw+jPDvQrbfeSnV1NfDHnay6uppbb701zbLMzPo1nIDqBDoj4plk/QEKgfV239Bd8nNT8vwGYFbR62cmbVYmCxYs4Pbbb983zXzSpEncfvvtvv2GmWXSkIf4IuItSeslfSwi/gU4D3g5eSwEbk5+Ppy85BEKZ8bfB5wJvOcDv+Xn+0GZHTkP66VjuLP4GoF7k6mwc4GbKATTZyS9Cnw6WQd4FHgNWAfcAfzdMD/bhsDX4jM7fANNKfdU8/IY1pUkIuJ5oL9LupzXz7YBXDmcz7PhaW1tZfHixezatYve3l5eeeUVFi9eDOBeldkAHEbp8ZUkcmTJkiVs376dadOmUVFRwbRp09i+fTtLlixJuzSzzPJ5UOlxQOXI1q1bmTx5MitXrqSrq4uVK1cyefJktm71nR7M+uPzoNLlgMqZ888/n8bGRiZMmEBjYyPnn39+2iWZZZ4vc5QOB1TOrFq1ii1bttDb28uWLVtYtWpV2iWZmfXLAZUjkogI9uzZQ0VFBXv27CEiPFxhZpnkgMqRiKC6uppt27bR29vLtm3bqK6u9rCF2SF4gkQ6HFA5M3HiRObMmYMk5syZw8SJE9MuySyzfB5UunxH3Rypqqo66N5Pe/fuparK/wzMBuIwSo//MuVIT08PO3fupKuri4hg/fr19PT0eNjCbBD97R8OrfJwQOVIZWUlFRUVRAQ9PT1UVFRQWVlJb29v2qWZZdJg50E5pErPx6ByZO/evXR3d+93JYnu7m7f8t3sEHweVDocUDkzbtw43nnnHXp7e3nnnXcYN25c2iWZmfXLAZUzu3fv3q8HtXv37rRLMjPrl49B5ZCHK8yOjCcSpcM9qJwZN24cW7duJSLYunWrh/jMBuHzoNLlHlTOdHd3U1FR+F7S29vrGXxmh+AwSo8DKkcqKyvp6emhp6cHYN/PysrKNMsyyzSfB5UeD/HlSF8gHW67Wd75flDpckDl0HHHHUdFRQXHHXdc2qWYjQqeWJQOB1TOVFZW8tZbb9Hb28tbb73l4T0zyywHVM709PRwzDHHUFFRwTHHHOPhPTPLLE+SyCEPV5gdGR9zSod7UDm0Y8cOIoIdO3akXYpZpvk8qHQ5oMxSJmmFpE2SXixqmyrpMUmvJj+npFmjWRocUDnUN1zhYYvMuAu44IC264HHI+IU4PFk3crM08zT5YDKob7hCQ9TZENEPAlsPaD5YuDuZPluYH45a7L9+bhtOoYdUJIqJf1G0k+T9ZMlPSNpnaT7JY1L2scn6+uS5+cM97PNxrAZEbExWX4LmDHQhpIWSVorae3mzZvLU51ZGYxED+oqoKNo/Rbgtoj4E2Ab0JC0NwDbkvbbku3M7BCi8LV9wK/uEbE8Iuoiom769OllrMystIYVUJJmAv8R+H6yLuAvgAeSTYqHJoqHLB4AzpMHcs0G8rak4wGSn5tSrifXJO17WPkMtwf1LeBaoO+S2NOAdyOi7x7incCJyfKJwHqA5Pn3ku334+EKMwAeARYmywuBh1OsJbc8zTxdQw4oSX8FbIqI50awHg9XWO5IagV+BXxMUqekBuBm4DOSXgU+naxbCoonSHiiRHkN50oS5wCfk/RZYALwIeB2YLKkqqSXNBPYkGy/AZgFdEqqAj4MvDOMzzcbEyJiwQBPnVfWQswyZsg9qIi4ISJmRsQc4DJgdUR8EWgDLkk2Kx6aKB6yuCTZ3l9FzMysX6U4D+o64GpJ6ygcY2pJ2luAaUn71fjEQzMzG8SIXCw2Ip4AnkiWXwPO6GebLuA/jcTnmZmVwlBn6XkwqDR8NXMzs8RgQSPJQVRmvtSRmZllkgPKzMwyyQFlZmaZ5IAyM7NMckCZmVkmOaDMzCyTHFBmZpZJDigzM8skB5SZmWWSA8rMzDLJAWVmZpnkgDIzs0xyQJmZWSY5oMzMLJMcUGZmlkkOKDMzyyQHlJmZZZIDyszMMskBZWZmmeSAMjOzTHJAmZlZJjmgzMwskxxQZmaWSQ4oMzPLpCEHlKRZktokvSzpJUlXJe1TJT0m6dXk55SkXZK+LWmdpBckfWKkfgkzMxt7htOD2gtcExGnAmcBV0o6FbgeeDwiTgEeT9YBLgROSR6LgO8N47PNzGyMG3JARcTGiPh1srwd6ABOBC4G7k42uxuYnyxfDNwTBU8DkyUdP9TPNzOzsa1qJN5E0hzgdOAZYEZEbEyeeguYkSyfCKwvelln0raxqA1Jiyj0sJg9e/ZIlGc2akn6A7Ad6AH2RkRduhWZlc+wJ0lIOhp4EPhqRLxf/FxEBBBH8n4RsTwi6iKibvr06cMtz2wsmBcRcx1OljfDCihJ1RTC6d6I+FHS/Hbf0F3yc1PSvgGYVfTymUmbmZnZQYYzi09AC9AREd8seuoRYGGyvBB4uKj9b5LZfGcB7xUNBZpZ/wL4haTnkuHvg0haJGmtpLWbN28uc3mj09SpU5F0RA/giF8zderUlH/T0W04x6DOAS4Hfivp+aTtRuBmYJWkBuB14PPJc48CnwXWAR8AXx7GZ5vlRX1EbJD0b4DHJP0uIp4s3iAilgPLAerq6o5oSD2vtm3bRuEIRGn1BZsNzZADKiLagYH+65/Xz/YBXDnUzzPLo4jYkPzcJOnHwBnAk4O/ymxs8JUkzDJK0iRJx/QtA+cDL6ZblVn5jMg0czMriRnAj5NhoipgZUT8LN2SzMrHAWWWURHxGvDxtOswS4uH+MzMLJMcUGZmlkkOKDMzyyQHlJmZZZIDyszMMskBZWZmmeSAMjOzTHJAmZlZJjmgzMwsk3wlCTPLnfjah+DrHy7P59iQOaDGuMO93P+B25XjVgRmadF/e79st9uIr5f8Y8YsB9QYV7wTDhZWDiQzyxofgzIzs0xyQOXIQL0k957MLIs8xJczfWEkycFkZpnmHpSZmWWSA8rMzDLJQ3xjwNSpU9m2bdsRv+5wp6D3mTJlClu3bj3izzHLoiP99z8UU6ZMKflnjGUOqDFg27ZtZTunw2wsGMr+4uO25echPjMzyyQHlJmZZZKH+MYAX1fMzMaisgeUpAuA24FK4PsRcXO5axhrfF0xMxuLyhpQkiqB7wKfATqBZyU9EhEvl7OOscgzksxsrCl3D+oMYF1EvAYg6T7gYsABNQyekWRmY1G5A+pEYH3ReidwZplryJXBela+urnZ/g41EjHQ895fSiNzkyQkLQIWAcyePTvlakY/7zhmh8/7S7aUe5r5BmBW0frMpG2fiFgeEXURUTd9+vSyFmdmZtlR7oB6FjhF0smSxgGXAY+UuQYzMxsFyjrEFxF7JS0Bfk5hmvmKiHipnDWYmdnoUPYrSUTEoxHx0Yj4SEQ0l/vzzUYTSRdI+hdJ6yRdn3Y9ZuXkSx2ZZVTReYMXAqcCCySdmm5VZuXjgDLLrn3nDUbEHqDvvEGzXHBAmWVXf+cNnnjgRpIWSVorae3mzZvLVpxZqTmgzEY5n5phY5UDyiy7DnneoNlYpiyfOS1pM/B62nWMUccCW9IuYow6KSKG3ZWRVAW8ApxHIZieBb4w2KkZ3mdKyvtM6fS7z2TuUkfFRmInt/5JWhsRdWnXYQMbynmD3mdKx/tM+WU6oMzyLiIeBR5Nuw6zNPgYlJmZZZIDKr+Wp12A2SjjfabMMj1JwszM8ss9KDMzyyQHlJmZZZIDKmckrZC0SdKLaddiNhp4n0mPAyp/7gIuSLsIs1HkLrzPpMIBlTMR8SSwNe06zEYL7zPpcUCZmVkmOaDMzCyTHFBmZpZJDigzM8skB1TOSGoFfgV8TFKnpIa0azLLMu8z6fGljszMLJPcgzIzs0xyQJmZWSY5oMzMLJMcUGZmlkkOKDMzyyQHlJmZZZIDyszMMun/A6aQ2sGfzCn5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3040579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614eb860",
   "metadata": {},
   "source": [
    "얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하는 편이 객관적으로 길이를 결정하는 데 도움이 될거예요. 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4544de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5ca37d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6feb",
   "metadata": {},
   "source": [
    "### 우리는 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제할게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35303d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fe236",
   "metadata": {},
   "source": [
    "# 시작 토큰과 종료 토큰 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7254b9",
   "metadata": {},
   "source": [
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있어요. 이번 실습에서는 시작 토큰은 sostoken, 종료 토큰은 eostoken이라 임의로 명명하고 앞, 뒤로 추가할 거예요. 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input, 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target이라고 이름을 정했어요. 두 개의 문장 모두 Summary 열로부터 만들 거예요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e67e4506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87570793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e38196",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터를 분리하는 방법은 분리 패키지를 사용하는 방법, 또는 직접 코딩을 통해서 분리하는 방법 등 여러 가지 방법이 있을 텐데 여기서는 직접 해볼게요. 우선, encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f33368d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  774 54055  2264 ... 23059 25589  8313]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a05abb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa336b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef29c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008e39d",
   "metadata": {},
   "source": [
    "# 8-7. 데이터 전처리하기 (3) 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3059ac0",
   "metadata": {},
   "source": [
    "이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어 주어야 해요. 이를 위해서는 각 단어에 고유한 정수를 맵핑하는 작업이 필요해요. 이 과정을 단어 집합(vocabulary) 을 만든다고 표현해요. 훈련 데이터에 대해서 단어 집합을 만들어볼게요. 우선, 원문에 해당되는 encoder_input_train에 대해서 단어 집합을 만들게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23f69f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd996f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 32014\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23781\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8233\n",
      "단어 집합에서 희귀 단어의 비율: 74.28312613231711\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.384776110465931\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0236825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc72db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75, 153, 7, 686, 59, 893, 91, 294, 199, 72, 786, 345, 265, 65, 774, 2434, 652, 132, 327, 1006, 56, 7, 265, 369, 117, 45, 296, 295, 75, 153], [453, 250, 145, 3603, 10, 994, 1067, 72, 1039, 809, 612, 274, 439, 1547, 4621, 13, 57, 72, 989, 582, 510, 1908, 3667, 970, 510, 453, 1435, 655, 166, 2435, 1633, 1, 2509, 735, 1634, 5434, 253, 1215], [210, 6, 2963, 703, 2057, 151, 2963, 703, 2057, 497, 443, 675, 254, 4, 3, 1040, 3748, 838, 86, 216]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f944c909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfecfa40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10453\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8088\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2365\n",
      "단어 집합에서 희귀 단어의 비율: 77.37491629197359\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.903528337797222\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef583cd",
   "metadata": {},
   "source": [
    "장 빈도가 5회 이하인 단어들은 단어 집합에서 약 77%를 차지하고 있네요. 하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 5.87%밖에 되지 않아요. 아까 했던 것과 동일하게 이 단어들은 모두 제거할게요. 어림잡아 2,000을 단어 집합의 크기로 제한할게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b31d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 41, 108], [1, 430, 555], [1, 1659, 556, 1107, 387, 686], [1, 4, 49, 16], [1, 308, 4, 35]]\n",
      "target\n",
      "decoder  [[41, 108, 2], [430, 555, 2], [1659, 556, 1107, 387, 686, 2], [4, 49, 16, 2], [308, 4, 35, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e4430",
   "metadata": {},
   "source": [
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있어요. 이 현상은 길이가 상대적으로 길었던 원문(Text)의 경우에는 문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(Summary)의 경우에는 이 현상이 굉장히 두드러졌을 가능성이 높겠죠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86159c",
   "metadata": {},
   "source": [
    "요약문에서 길이가 0이 된 샘플들의 인덱스를 받아와볼게요. 여기서 주의할 점은 요약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않아요. 그래서 이제 길이가 0이 된 요약문의 실제 길이는 1로 나올 거예요. 길이 0이 된 decoder_input에는 sostoken, decoder_target에는 eostoken만 남아 있을 테니까요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d7163",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장해볼게요. 이 샘플들은 모두 삭제할 거예요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b94ccc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1268\n",
      "삭제할 테스트 데이터의 개수 : 342\n",
      "훈련 데이터의 개수 : 51387\n",
      "훈련 레이블의 개수 : 51387\n",
      "테스트 데이터의 개수 : 12821\n",
      "테스트 레이블의 개수 : 12821\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60e4e6",
   "metadata": {},
   "source": [
    "### 패딩하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d37e1b",
   "metadata": {},
   "source": [
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해주어야 해야 해요. 아까 정해두었던 최대 길이로 패딩 해 줄 거에요. 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "302c9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c388bb4",
   "metadata": {},
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc7ff19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e4e37",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의했어요. hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터에요. 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 개수라고 이해하면 돼요. 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니에요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5be05",
   "metadata": {},
   "source": [
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있죠. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?\n",
    "\n",
    "또한 LSTM은 dropout 뿐 아니라 recurrent dropout까지 사용해요. 일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 모델의 과적합(overfitting)을 해결해주는 방법이에요.\n",
    "\n",
    "반면 recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식이에요. 즉 time step의 입력을 랜덤으로 생략해 주는 거죠. recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지할 수 있다고 해요.\n",
    "\n",
    "아래 그림은 일반적인 dropout과, dropout과 recurrent dropout을 동시에 사용한 것을 시각적으로 표현한 것입니다. 색이 있는 화살표는 dropout을 나타낸 것이에요. (색이 다른 것은 다른 dropout mask를 사용했다는 표시인데, 지금은 그냥 넘어가셔도 됩니다.) 우리가 현재 사용한 LSTM은 dropout과 recurrent dropout을 모두 사용했으니 오른쪽 그림과 같은 형태겠군요. 참고로 dropout과 recurrent dropout을 모두 사용한 것을 Variational Dropout이라고도 해요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4952bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e89eae8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf8bb9",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야 한다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32df6845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,145,360\n",
      "Trainable params: 4,145,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff92e63",
   "metadata": {},
   "source": [
    "위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고, 어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동하고 있어요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33721e76",
   "metadata": {},
   "source": [
    "# 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68bab675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 137s 639ms/step - loss: 2.7028 - val_loss: 2.4144\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 127s 633ms/step - loss: 2.3689 - val_loss: 2.2655\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 127s 630ms/step - loss: 2.2233 - val_loss: 2.1338\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 127s 631ms/step - loss: 2.1033 - val_loss: 2.0599\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 129s 640ms/step - loss: 2.0213 - val_loss: 2.0002\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 129s 641ms/step - loss: 1.9582 - val_loss: 1.9619\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 128s 638ms/step - loss: 1.9054 - val_loss: 1.9334\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 127s 633ms/step - loss: 1.8602 - val_loss: 1.9142\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 127s 634ms/step - loss: 1.8203 - val_loss: 1.8915\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 128s 635ms/step - loss: 1.7843 - val_loss: 1.8808\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 128s 639ms/step - loss: 1.7511 - val_loss: 1.8686\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 128s 637ms/step - loss: 1.7206 - val_loss: 1.8636\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 129s 641ms/step - loss: 1.6925 - val_loss: 1.8556\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 129s 640ms/step - loss: 1.6657 - val_loss: 1.8521\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 129s 643ms/step - loss: 1.6399 - val_loss: 1.8511\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 129s 643ms/step - loss: 1.6144 - val_loss: 1.8480\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 128s 638ms/step - loss: 1.5927 - val_loss: 1.8464\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 129s 641ms/step - loss: 1.5696 - val_loss: 1.8495\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 128s 639ms/step - loss: 1.5483 - val_loss: 1.8499\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c888c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb23087",
   "metadata": {},
   "source": [
    "# 8-10. 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef73899",
   "metadata": {},
   "source": [
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비해 둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff008ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d4a7d",
   "metadata": {},
   "source": [
    "seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 한다는 것, 알고 계시나요?\n",
    "\n",
    "훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한 번에 비교할 수 있으므로, 인코더와 디코더를 엮은 통짜 모델 하나만 준비했습니다.\n",
    "\n",
    "그러나 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 합니다. 이때는 인코더 모델과 디코더 모델을 분리해서 설계합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd072cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ac9c1",
   "metadata": {},
   "source": [
    "### 출력층을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4b427ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0003f3",
   "metadata": {},
   "source": [
    "### 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1ac6fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de41f8b",
   "metadata": {},
   "source": [
    "# 8-11. 모델 테스트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f12073",
   "metadata": {},
   "source": [
    "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 편하겠죠. 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어볼게요. 함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외하고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외하도록 만들 거예요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "843d6358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da5cc62a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : toy sturdy well puppy took time figure three games certainly brain small pieces owner must involved game sure puppy eat dog much prefers ball treats inside fall noses around keeps amused least minutes \n",
      "실제 요약 : way too easy \n",
      "예측 요약 :  my dog loves it\n",
      "\n",
      "\n",
      "원문 : still great reordered increase since may nuts product good wow good love place find stores changing versions something good change long shelf life never make \n",
      "실제 요약 : great but as of \n",
      "예측 요약 :  the best\n",
      "\n",
      "\n",
      "원문 : excellent cereal get shipment every months boxes damaged kashi golean good source protein fiber recommend fruit mixing another cereal little mild tasting \n",
      "실제 요약 : kashi cereal oz \n",
      "예측 요약 :  great cereal\n",
      "\n",
      "\n",
      "원문 : usually order bustelo decaffeinated coffee used taste regular espresso tried lavazza decaf espresso extremely disappointed really obvious taste decaffeinated tastes like processed ordered pack would really like send back three opened yet \n",
      "실제 요약 : tastes \n",
      "예측 요약 :  coffee beans\n",
      "\n",
      "\n",
      "원문 : want good quick cooked sauce without excess acidity ones use real san marzano beware \n",
      "실제 요약 : best of the canned tomatoes \n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : pumpkin great dog really love fair compared others would reccommend product well seller quickly well \n",
      "실제 요약 : good \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : tea excellent top quality hibiscus dont use much thought would cup quarts water steeped hour lovely \n",
      "실제 요약 : delicious \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : favorite tea vanilla helps mellow bergamot gives tea creamy flavor acidic flavors \n",
      "실제 요약 : my favorite \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : great pasta tastes regular pasta better really like \n",
      "실제 요약 : perfect \n",
      "예측 요약 :  pasta\n",
      "\n",
      "\n",
      "원문 : great item makes pretty decent products need others said countless uses item even add water drink lemonade although primary use fruit \n",
      "실제 요약 : great value \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : really like flavor one low acidity still full flavor every morning trouble finding another one like much \n",
      "실제 요약 : love it \n",
      "예측 요약 :  great flavor\n",
      "\n",
      "\n",
      "원문 : trying several packages signature blend different product found discs defective grounds ended bottom cup rest coffeemaker notified gevalia month ago offered explanation solution problem problem brand disc gevalia blends extremely frustrating considering paying extra gevalia name would recommend maxwell house seattle best far superior discs grounds bottom cup \n",
      "실제 요약 : defective discs \n",
      "예측 요약 :  not worth the money\n",
      "\n",
      "\n",
      "원문 : drink three cups day made one oolong tea bag one green tea bag large mug believe helped lose lbs last five months drink without sweeteners also cold price reasonable taste mild \n",
      "실제 요약 : great product \n",
      "예측 요약 :  love this tea\n",
      "\n",
      "\n",
      "원문 : heard dr oz ladies taste test really seemed enjoy prepared smells bit like weeds grass taste favorable \n",
      "실제 요약 : organic tea not that great \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : boxes apple chips arrived dented bags many broken chips flimsy packaging cannot stand ups \n",
      "실제 요약 : chips great but packaging lousy \n",
      "예측 요약 :  not as good as the\n",
      "\n",
      "\n",
      "원문 : month old loves flavor plum organics born lip palate allowed eat bottle mix formula loves go packets plum organics food everyday thrilled find flavor liked provided green veggies surprised expensive amazon never pay per packet babies us sale frequently \n",
      "실제 요약 : convenient nutrition but cheaper at babies us \n",
      "예측 요약 :  great for babies\n",
      "\n",
      "\n",
      "원문 : although seems like great product definitely minced cans say minced ground beef cat likes minced chunks ground although eat ground cat food sometimes inviting delicious yet walks away hate packaging lies contents product shipping speedy value great stuck food cat wont eat \n",
      "실제 요약 : not this is ground beef \n",
      "예측 요약 :  my cat loves it\n",
      "\n",
      "\n",
      "원문 : really eat breakfast cereal review husband favorite cereal cereal available halloween purchased boxes back october thanksgiving gone wait next october purchase get online someone general mills explain behind \n",
      "실제 요약 : husband favorite \n",
      "예측 요약 :  great cereal\n",
      "\n",
      "\n",
      "원문 : pretzels great purchased husband longer find grocery store highly recommend anyone likes spicy foods \n",
      "실제 요약 : excellent \n",
      "예측 요약 :  the best\n",
      "\n",
      "\n",
      "원문 : twin girls love wanted give fish ready prepare perfect tried sprout pouch meals really like bit wary pouches easier empty texture great month olds girls eat right \n",
      "실제 요약 : easy and good \n",
      "예측 요약 :  my baby loves it\n",
      "\n",
      "\n",
      "원문 : know applesauce could hit house daughter loves stuff clever package makes mess take car snack wish nutritional value needs fortified vitamins make five stars \n",
      "실제 요약 : daughter loves this stuff \n",
      "예측 요약 :  great for babies\n",
      "\n",
      "\n",
      "원문 : absolutely great giving medicine pets even usually super finicky cat loves chicken flavor little nuggets lifesavers try like \n",
      "실제 요약 : happy kitty happy \n",
      "예측 요약 :  my cat loves it\n",
      "\n",
      "\n",
      "원문 : taste like tang expensive fan tang love tang want convenience might drink \n",
      "실제 요약 : not bad nothing special about it \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : purchased jar product nowhere near good dry texture coarse gritty really need stir things enjoy oatmeal smoothies etc eat right jar brand still gives things delicious coconut taste brands superior texture \n",
      "실제 요약 : dry and \n",
      "예측 요약 :  the best cereal ever\n",
      "\n",
      "\n",
      "원문 : good blend nice body hearty flavor definitely worth try yet still prefer starbucks medium breakfast blend buy every change pace \n",
      "실제 요약 : tasty blend \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : received gummies quickly incredibly fresh lovely cannot wait try kinds \n",
      "실제 요약 : soft chewy flavorful perfect \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : love tea especially enjoy tea enjoying nice hot bath relaxing aromatic family enjoys iced tea \n",
      "실제 요약 : orange spice tea \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : cocoa may bit expensive usual grocery store variety really changes taste item deliciously dark complex wonderful \n",
      "실제 요약 : worth every \n",
      "예측 요약 :  great cocoa\n",
      "\n",
      "\n",
      "원문 : comparison packaged skins store one taste hooked \n",
      "실제 요약 : you must try these \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : watching dog itchy skin years hundreds dollars useless vet bills finally figured dog food allergies go figure happy hips makes baby happy turn makes happy \n",
      "실제 요약 : the best dog food ever \n",
      "예측 요약 :  great for dogs\n",
      "\n",
      "\n",
      "원문 : worth price people run company must spent much time working fields hot sun lost popcorn received stale tough freshness dates anywhere bag even sealed comes plastic bag wire tie like loaf bread obviously shelf long dried disappointing pay top price sent company email even answer \n",
      "실제 요약 : inferior product \n",
      "예측 요약 :  great chips\n",
      "\n",
      "\n",
      "원문 : tea fine taste indian spiced chai tea twinings used liked old one lot better could find \n",
      "실제 요약 : not the same \n",
      "예측 요약 :  tea\n",
      "\n",
      "\n",
      "원문 : sometimes trouble finding happy see amazon \n",
      "실제 요약 : love this tea \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : china thing scared minute tasty one word caution lot product per circumstances freeze leftover product rice takes terrible texture inedible \n",
      "실제 요약 : excellent \n",
      "예측 요약 :  not for\n",
      "\n",
      "\n",
      "원문 : love peach flavor every rates different tried different flavors result taste great get right \n",
      "실제 요약 : quality control is non with this brand \n",
      "예측 요약 :  love this stuff\n",
      "\n",
      "\n",
      "원문 : nuts opened package rancid amazon nice us money \n",
      "실제 요약 : rancid nuts \n",
      "예측 요약 :  not fresh\n",
      "\n",
      "\n",
      "원문 : yum yum yum love almonds love cocoa flavor great snack blame brother got addicted love yum \n",
      "실제 요약 : yumm \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : good sandwiches oatmeal good cooling know would buy bit certainly interesting \n",
      "실제 요약 : interesting pb \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : looking sweet try cookie extra nice crunch buy cookies carton last one month husband likes morning coffee satisfied cookies would buy mary \n",
      "실제 요약 : really light cookie \n",
      "예측 요약 :  good cookie\n",
      "\n",
      "\n",
      "원문 : love fresh cinnamon gum tastes great good breath flavor last long time pieces plenty chew \n",
      "실제 요약 : delicious \n",
      "예측 요약 :  great gum\n",
      "\n",
      "\n",
      "원문 : serving baked goodies good old days family makes happy could find mincemeat grocery stores holiday season remembered amazon would probably answer problem solved would proud \n",
      "실제 요약 : little box full of \n",
      "예측 요약 :  good product\n",
      "\n",
      "\n",
      "원문 : product gives great energy boost crashing calories best tasting drink diet problem taste \n",
      "실제 요약 : good energy \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : tried use grocery store oil popcorn popper always tasted stale bit like movie theater popcorn decided try party made world difference tasted like fresh popped corn theater packs easy use cut across top dump packets heated popper definitely buy \n",
      "실제 요약 : great taste and easy to use \n",
      "예측 요약 :  great popcorn\n",
      "\n",
      "\n",
      "원문 : great son likes best better quaker oats brand special plan works well \n",
      "실제 요약 : good \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : absolutely melt mouth soft smooth chocolates tastes like high end chocolates europe cannot go wrong fresh great quality \n",
      "실제 요약 : chocolate \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : food full chunks cats love normally variety top quality pate foods wanted give something chew would take longer minutes eat stuff kitty dreams must made sure mine anyway \n",
      "실제 요약 : my cats love this stuff \n",
      "예측 요약 :  cats love it\n",
      "\n",
      "\n",
      "원문 : one coworkers brought light delicious taste kinda lightly sweet salty cracker light tasting unique product get big fan filler foods hey need quick snack work without going overboard calories get thank taste buds \n",
      "실제 요약 : light and delicious \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : purchase variety pack reviewing ingredients really fruit eat organic great mid day snack work recommending everyone delivery could quicker easier \n",
      "실제 요약 : great day snack \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : liked noodles intolerance gluten eat \n",
      "실제 요약 : noodles \n",
      "예측 요약 :  pasta\n",
      "\n",
      "\n",
      "원문 : product great price right free shipping icing cake \n",
      "실제 요약 : peach green tea \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
